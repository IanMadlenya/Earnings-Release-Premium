---
title: "R Notebook"
output: html_notebook
---

 
```{r}
packages.used=c("gbm", "caret","DMwR" ,"nnet","randomForest","e1071")

# check packages that need to be installed.
packages.needed=setdiff(packages.used, 
                        intersect(installed.packages()[,1], 
                                  packages.used))
# install additional packages
if(length(packages.needed)>0){
  install.packages(packages.needed, dependencies = TRUE)
}
```

```{r}

setwd("~/Spr2017-proj5-grp15/data/observation")
short_after_selected <- read.csv("short_after20.csv")
short_after_selected$X <- ifelse(short_after_selected$RETURN >0, 1,0)
short_after_selected <- na.omit(short_after_selected)
short_after_selected <- short_after_selected[,-1]
short_after_selected <- short_after_selected[,-11]
test.index <- sample(1:1500,300,replace = F)
test.sas <- short_after_selected[test.index,]

test.sas.x <- test.sas[,-1]
train.sas <- short_after_selected[-test.index,]


colnames(train.sas)[1] <-"y"
colnames(test.sas)[1] <-"y"

train.sas$y <- as.factor(train.sas$y)
```

```{r}
# SVM

model.svm <- svm(y ~ ., data = train.sas, cost = 64, gamma = 0.4)
pre.svm <- predict(model.svm,test.sas.x,type="class")
table(pre.svm,test.sas$y)
```

```{r}
svm_tune <- tune(svm, 
                 y~DY+EBITG+EV2EBITDA+M2B+MOMENTUM+PB+PE+PF+PS+days,
                 data=train.sas,
                 kernel="radial", 
                 ranges=list(cost=2^(5:8), 
                             gamma=c(0.4,0.5,0.6)))

print(svm_tune)
plot(svm_tune)
```

```{r}
# netural network
model.nnet <- nnet(y ~ ., data = train.sas, linout = F,
                     size = 10, decay = 0.001, maxit = 200,
                     trace = F, MaxNWts=6000)
pre.nnet <- predict(model.nnet,test.sas.x,type="class")
table(pre.nnet,test.sas$y)

```

```{r}
tune.nnet(y ~ ., data = train.sas, linout = F,
+           size = 1:10, decay = 0.001:0.1, maxit = 200,
+           trace = F, MaxNWts=6000)
```

```{r}
# Random Forest 
y.index<- which(colnames(train.sas)=="y")
bestmtry <- tuneRF(y= train.sas$y, x= train.sas[,-y.index], stepFactor=1.5, improve=1e-5, ntree=600)
best.mtry <- bestmtry[,1][which.min(bestmtry[,2])]
model.rf <- randomForest(y ~ ., data = train.sas, ntree=600, mtry=best.mtry, importance=T)
pre.rf <- predict(model.rf,test.sas.x,type="class")
table(pre.rf,test.sas$y)
```


```{r}
# Majority Vote
pre=(as.numeric(as.character(bp.pre))+as.numeric(as.character(log.pre))+as.numeric(as.character(svm.pre)))
pre=ifelse(pre>=2,1,0)
table(pre,test$y)

```


```{r}

```


```{r}

```

